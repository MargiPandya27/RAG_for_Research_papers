Source: Pyramid Scene Parsing Network
Section Titles: ['Abstract', 'Introduction', 'methods', 'methods', 'results', 'Results', 'methods', 'methods', 'methods', 'results']
Start Index: 3000
--------------------------------------------------
ferent from other datasets, ADE20K is more challenging for the up to 150 classes and diverse scenes with a total of 1,038 image-level labels. The challenge data is divided into 20K/2K/3K images for training, validation and testing. Also, it needs to parse both objects and stuff in the scene, which makes it more difﬁcult than other datasets. For eval- uation, both pixel-wise accuracy (Pixel Acc.) and mean of class-wise intersection over union (Mean IoU) are used. Ablation Study for PSPNet To evaluate PSPNet, we con- duct experiments with several settings, including pooling types of max and average, pooling with just one global fea- ture or four-level features, with and without dimension re- duction after the pooling operation and before concatena- tion. As listed in Table 1, average pooling works better than max pooling in all settings. Pooling with pyramid parsing outperforms that using global pooling. With dimension re- duction, the performance is further enhanced. With our pro- posed PSPNet, the best setting yields results 41.68/80.04 in terms of Mean IoU and Pixel Acc. (%), exceeding global average pooling of 40.07/79.52 as idea in Liu et al. by 1.61/0.52. And compared to the baseline, PSPNet outper- forming it by 4.45/2.03 in terms of absolute improvement and 11.95/2.60 in terms of relative difference. Ablation Study for Auxiliary Loss The introduced aux- iliary loss helps optimize the learning process while not in- ﬂuencing learning in the master branch. We experiment with setting the auxiliary loss weight α between 0 and 1 and show the results in Table 2. The baseline uses ResNet50- based FCN with dilated network, with the master branch’s softmax loss for optimization. Adding the auxiliary loss Loss Weight α Mean IoU(%) Pixel Acc.(%) ResNet50 (without AL) 35.82 77.07 ResNet50 (with α = 0.3) 37.01 77.87 ResNet50 (with α = 0.4)