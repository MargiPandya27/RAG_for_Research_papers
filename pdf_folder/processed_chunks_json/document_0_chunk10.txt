Source: Image Segmentation
Section Titles: ['Abstract', 'Introduction', 'Conclusion']
Start Index: 2250
--------------------------------------------------
better than the sliding-window convolutional network result by Ciresan et al. , whose best submission had a warping error of 0.000420 and a rand error of 0.0504. In terms of rand error the only better performing Table 1. Ranking on the EM segmentation challenge (march 6th, 2015), sorted by warping error. Rank Group name Warping Error Rand Error Pixel Error ** human values ** 0.000005 0.0021 0.0010 1. u-net 0.000353 0.0382 0.0611 2. DIVE-SCI 0.000355 0.0305 0.0584 3. IDSIA 0.000420 0.0504 0.0613 4. DIVE 0.000430 0.0545 0.0582 ... 10. IDSIA-SCI 0.000653 0.0189 0.1027 7 a b c d Fig. 4. Result on the ISBI cell tracking challenge. (a) part of an input image of the “PhC-U373” data set. (b) Segmentation result (cyan mask) with manual ground truth (yellow border) (c) input image of the “DIC-HeLa” data set. (d) Segmentation result (random colored masks) with manual ground truth (yellow border). Table 2. Segmentation results (IOU) on the ISBI cell tracking challenge 2015. Name PhC-U373 DIC-HeLa IMCB-SG (2014) 0.2669 0.2935 KTH-SE (2014) 0.7953 0.4607 HOUS-US (2014) 0.5323 - second-best 2015 0.83 0.46 u-net (2015) 0.9203 0.7756 algorithms on this data set use highly data set speciﬁc post-processing methods1 applied to the probability map of Ciresan et al. . We also applied the u-net to a cell segmentation task in light microscopic im- ages. This segmenation task is part of the ISBI cell tracking challenge 2014 and 2015 . The ﬁrst data set “PhC-U373”2 contains Glioblastoma-astrocytoma U373 cells on a polyacrylimide substrate recorded by phase contrast microscopy (see Figure 4a,b and Supp. Material). It contains 35 partially annotated train- ing images. Here we achieve an average IOU (“intersection over union”) of 92%, which is signiﬁcantly better than the second best algorithm with 83% (see Ta- ble 2). The second data set “DIC-HeLa”3 are