Source: Pyramid Scene Parsing Network
Section Titles: ['Abstract', 'Introduction', 'methods', 'methods', 'results', 'Results', 'methods', 'methods', 'methods', 'results']
Start Index: 2000
--------------------------------------------------
feature maps to get the same size feature as the original feature map via bilinear interpolation. Finally, different levels of features are concatenated as the ﬁnal pyramid pooling global feature. Noted that the number of pyramid levels and size of each level can be modiﬁed. They are related to the size of feature map that is fed into the pyramid pooling layer. The struc- ture abstracts different sub-regions by adopting varying-size pooling kernels in a few strides. Thus the multi-stage ker- nels should maintain a reasonable gap in representation. Our pyramid pooling module is a four-level one with bin sizes of 1×1, 2×2, 3×3 and 6×6 respectively. For the type of pooling operation between max and average, we perform extensive experiments to show the difference in Section 5.2. 3.3. Network Architecture With the pyramid pooling module, we propose our pyra- mid scene parsing network (PSPNet) as illustrated in Fig. 3. Given an input image in Fig. 3(a), we use a pretrained ResNet model with the dilated network strategy to extract the feature map. The ﬁnal feature map size is 1/8 of the input image, as shown in Fig. 3(b). On top of the Figure 4. Illustration of auxiliary loss in ResNet101. Each blue box denotes a residue block. The auxiliary loss is added after the res4b22 residue block. map, we use the pyramid pooling module shown in (c) to gather context information. Using our 4-level pyramid, the pooling kernels cover the whole, half of, and small portions of the image. They are fused as the global prior. Then we concatenate the prior with the original feature map in the ﬁnal part of (c). It is followed by a convolution layer to generate the ﬁnal prediction map in (d). To explain our structure, PSPNet provides an effective global contextual prior for