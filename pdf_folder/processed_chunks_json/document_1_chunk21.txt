Source: Pyramid Scene Parsing Network
Section Titles: ['Abstract', 'Introduction', 'methods', 'methods', 'results', 'Results', 'methods', 'methods', 'methods', 'results']
Start Index: 5000
--------------------------------------------------
are pro- vided for two settings in comparison, i.e., training with only ﬁne data or with both the ﬁne and coarse data. Methods trained using both ﬁne and coarse data are marked with ‘‡’. Detailed results are listed in Table 7. Our base model is ResNet101 as in DeepLab for fair comparison and the testing procedure follows Section 5.3. Statistics in Table 7 show that PSPNet outperforms other with notable advantage. Using both ﬁne and coarse data for training makes our method yield 80.2 accuracy. Several examples are shown in Fig. 8. Detailed per-class on testing set are shown in Table 8. 6. Concluding Remarks We have proposed an effective pyramid scene parsing network for complex scene understanding. The global pyra- Figure 8. Examples of PSPNet results on Cityscapes dataset. mid pooling feature provides additional contextual informa- tion. We have also provided a deeply supervised optimiza- tion strategy for ResNet-based FCN network. We hope the implementation details publicly available can help the com- munity adopt these useful strategies for scene parsing and semantic segmentation and advance related techniques. Acknowledgements We would like to thank Gang Sun and Tong Xiao for their help in training the basic classiﬁcation models, Qun Luo for technical support. This work is supported by a grant from the Research Grants Council of the Hong Kong SAR (project No. 2150760). Figure 9. Visual comparison on PASCAL VOC 2012 data. (a) Image. (b) Ground Truth. (c) FCN . (d) DPN . (e) DeepLab . (f) PSPNet. Method road swalk build. wall fence pole tlight sign veg. terrain sky person rider car truck bus train mbike bike mIoU CRF-RNN 96.3 73.9 88.2 47.6 41.3 35.2 49.5 59.7 90.6 66.1 93.5 70.4 34.7 90.1 39.2 57.5 55.4 43.9 54.6 62.5 FCN 97.4 78.4 89.2 34.9 44.2 47.4 60.1 65.0 91.4