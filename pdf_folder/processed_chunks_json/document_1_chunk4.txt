Source: Pyramid Scene Parsing Network
Section Titles: ['Abstract', 'Introduction', 'methods', 'methods', 'results', 'Results', 'methods', 'methods', 'methods', 'results']
Start Index: 750
--------------------------------------------------
work to learn the segmentation mask. Our baseline network is FCN and dilated network . Other work mainly proceeds in two directions. One line is with multi-scale feature ensembling. Since in deep networks, higher-layer feature contains more semantic meaning and less location information. Combin- ing multi-scale features can improve the performance. The other direction is based on structure prediction. The pioneer work used conditional random ﬁeld (CRF) as post processing to reﬁne the segmentation result. Following reﬁned networks via end-to-end model- ing. Both of the two directions ameliorate the localization ability of scene parsing where predicted semantic boundary ﬁts objects. Yet there is still much room to exploit necessary information in complex scenes. To make good use of global image-level priors for di- verse scene understanding, methods of extracted global context information with traditional features not from deep neural networks. Similar improvement was made 1https://github.com/hszhao/PSPNet under object detection frameworks . Liu et al. proved that global average pooling with FCN can improve semantic segmentation results. However, our experiments show that these global descriptors are not representative enough for the challenging ADE20K data. Therefore, dif- ferent from global pooling in , we exploit the capabil- ity of global context information by different-region-based context aggregation via our pyramid scene parsing network. 3. Pyramid Scene Parsing Network We start with our observation and analysis of represen- tative failure cases when applying FCN methods to scene parsing. They motivate proposal of our pyramid pooling module as the effective global context prior. Our pyramid scene parsing network (PSPNet) illustrated in Fig. 3 is then described to improve performance for open-vocabulary ob- ject and stuff identiﬁcation in complex scene parsing. 3.1. Important Observations The new ADE20K dataset contains 150 stuff/object category labels (e.g., wall, sky, and tree) and 1,038 image- level scene descriptors (e.g., airport terminal,