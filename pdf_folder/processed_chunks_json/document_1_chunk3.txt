Source: Pyramid Scene Parsing Network
Section Titles: ['Abstract', 'Introduction', 'methods', 'methods', 'results', 'Results', 'methods', 'methods', 'methods', 'results']
Start Index: 500
--------------------------------------------------
ﬁnal prediction more reliable. We also propose an optimization strategy with 1 arXiv:1612.01105v2 27 Apr 2017 deeply supervised loss. We give all implementation details, which are key to our decent performance in this paper, and make the code and trained models publicly available 1. Our approach achieves state-of-the-art performance on all available datasets. It is the champion of ImageNet scene parsing challenge 2016 , and arrived the 1st place on PASCAL VOC 2012 semantic segmentation benchmark , and the 1st place on urban scene Cityscapes data . They manifest that PSPNet gives a promising direction for pixel- level prediction tasks, which may even beneﬁt CNN-based stereo matching, optical ﬂow, depth estimation, etc. in follow-up work. Our main contributions are threefold. • We propose a pyramid scene parsing network to em- bed difﬁcult scenery context features in an FCN based pixel prediction framework. • We develop an effective optimization strategy for deep ResNet based on deeply supervised loss. • We build a practical system for state-of-the-art scene parsing and semantic segmentation where all crucial implementation details are included. 2. Related Work In the following, we review recent advances in scene parsing and semantic segmentation tasks. Driven by pow- erful deep neural networks , pixel-level prediction tasks like scene parsing and semantic segmen- tation achieve great progress inspired by replacing the fully-connected layer in classiﬁcation with the convolution layer . To enlarge the receptive ﬁeld of neural networks, of used dilated convolution. Noh et al. proposed a coarse-to-ﬁne structure with deconvolution net- work to learn the segmentation mask. Our baseline network is FCN and dilated network . Other work mainly proceeds in two directions. One line is with multi-scale feature ensembling. Since in deep networks, higher-layer feature contains more semantic meaning and less location information. Combin- ing multi-scale features can improve the