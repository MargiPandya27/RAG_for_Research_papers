Source: Pyramid Scene Parsing Network
Section Titles: ['Abstract', 'Introduction', 'methods', 'methods', 'results', 'Results', 'methods', 'methods', 'methods', 'results']
Start Index: 2750
--------------------------------------------------
and random resize between 0.5 and 2 for all datasets, and additionally add random rotation between - 10 and 10 degrees, and random Gaussian blur for ImageNet and PASCAL VOC. This comprehensive data augmentation scheme makes the network resist overﬁtting. Our network contains dilated convolution following . During the course of experiments, we notice that an ap- propriately large “cropsize” can yield good performance and “batchsize” in the batch normalization layer is of great importance. Due to limited physical memory on GPU cards, we set the “batchsize” to 16 during training. To achieve this, we modify Caffe from together with Method Mean IoU(%) Pixel Acc.(%) ResNet50-Baseline 37.23 78.01 ResNet50+B1+MAX 39.94 79.46 ResNet50+B1+AVE 40.07 79.52 ResNet50+B1236+MAX 40.18 79.45 ResNet50+B1236+AVE 41.07 79.97 ResNet50+B1236+MAX+DR 40.87 79.61 ResNet50+B1236+AVE+DR 41.68 80.04 Table 1. Investigation of PSPNet with different settings. Baseline is ResNet50-based FCN with dilated network. ‘B1’ and ‘B1236’ denote pooled feature maps of bin sizes {1 × 1} and {1 × 1, 2 × 2, 3 × 3, 6 × 6} respectively. ‘MAX’ and ‘AVE’ represent max pooling and average pooling operations individually. ‘DR’ means that dimension reduction is taken after pooling. The results are tested on the validation set with the single-scale input. branch and make it support batch normalization on data gathered from multiple GPUs based on OpenMPI. For the auxiliary loss, we set the weight to 0.4 in experiments. 5.2. ImageNet Scene Parsing Challenge 2016 Dataset and Evaluation Metrics The ADE20K dataset is used in ImageNet scene parsing challenge 2016. Dif- ferent from other datasets, ADE20K is more challenging for the up to 150 classes and diverse scenes with a total of 1,038 image-level labels. The challenge data is divided into 20K/2K/3K images for training, validation and testing. Also, it needs to parse both objects and stuff in the scene, which