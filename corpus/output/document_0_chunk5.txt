Source: document_0
Section Titles: []
Start Index: 1000
--------------------------------------------------
( ) as @xmath44 with norm given by @xmath45 the norm of @xmath46 satisfies @xmath47 to illustrate advantages of additive models , we provide two examples of comparing additive with product kernels . the first example deals with gaussian rbf kernels . all proofs will be given in section . let @xmath48 , @xmath49 ] let @xmath51 and @xmath52.\ ] ] the additive kernel @xmath53 is given by @xmath54 furthermore , the product kernel @xmath55 is the standard gaussian kernel given by @xmath56 define a gaussian function @xmath57 on @xmath58 ^ 2 ] and @xmath58^s. ] . if we take all the mercer kernels @xmath69 to be @xmath67 , then @xmath70 ] , consisting of all square integrable functions whose partial derivatives are all square integrable , contains discontinuous functions and is not an rkhs . denote the marginal distribution of @xmath6 on @xmath27 as @xmath75 . under the assumption that @xmath76 for each @xmath71 and that @xmath43 is dense in @xmath29 in the @xmath77-metric , it was proved in @xcite that @xmath78 in probability as long as @xmath79 satisfies @xmath80 and @xmath81 . the rest of the paper has the following structure . section contains our main results on learning rates for svms based on additive kernels . learning rates for quantile regression are treated as important special cases . section contains a comparison of our results with other learning rates published recently . section contains all the proofs and some results which can be interesting in their own . in this paper we provide some learning rates for the support vector machines generated by additive kernels for additive models which helps improve the quantitative understanding presented in @xcite . the rates are about asymptotic behaviors of the excess risk @xmath82 and take the form @xmath83 with @xmath84 .